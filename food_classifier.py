# -*- coding: utf-8 -*-
"""Food_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RBaILkwOYql20Tgu5Hxv6CKnpk_RYb3r

##Classifying stuff from PyTorch's built-in Food101 Dataset

3 stuff for now (pizza, steak, sushi)


Food101 has 101 different classes of food and 1000 images per class(750 training, 250 testing).

This dataset starts with 3 classes of food and only 10% of the images (~75 training and 25 testing)

Will scale up later, keeping it small to keep processing fast.
"""

import torch
from torch import nn
import numpy as np
import matplotlib.pyplot as plt

#Setting up device-agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"

"""##Getting Data from github

"""

import requests
import zipfile
from pathlib import Path

#Path to data folder
data_path = Path("data/")
image_path = data_path / "pizza_steak_sushi"

#If the image folder doesn't exists, download it and prepare it...
if image_path.is_dir():
    print(f"{image_path} already exists, skipping download.")
else:
    print("Downloading pizza, steak, sushi data...")
    image_path.mkdir(parents=True, exist_ok=True)

with open(data_path / "pizza_steak_sushi.zip", "wb") as f:
    request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
    f.write(request.content)

#Unzip pizza, steak and sushi data
with zipfile.ZipFile(data_path / "pizza_steak_sushi.zip", "r") as zip_ref:
    zip_ref.extractall(image_path)

#Standard way to arrange data in training and testing
train_dir=image_path/"train"
test_dir=image_path/"test"

"""## Visualising a random image

1. Get all of the image paths
2. Pick a random image path using random.choice()
3. Get the image calss name using pathlib.Path.parent.stem
4. Open the image using Python's PIL(Pillow)
5. Show the image
"""

import random
from PIL import Image

# Get all image paths
image_paths = list(image_path.glob("*/*/*.jpg"))

# Pick a random image path
img_path = random.choice(image_paths)

# Get the image class from path name
class_name = img_path.parent.stem
print(class_name)

# Open the image
img = Image.open(img_path)

# Show the image
img

"""## Transforming data

1. Turn the target data into tensors
2. Turn it into 'torch.utils.data.Dataset' and subsequently a 'torch.utils.data.DataLoader' , we call them Dataset and DataLoader

change datasize to (224,224)
"""

from torch.utils.data import DataLoader
from torchvision import transforms

##Transforming data using torchvision.transforms
data_transform=transforms.Compose([
    transforms.Resize(size=(224,224)),
    #Flip the images randomly on the horizontal axis(data augmentation for more diversity)
    transforms.RandomHorizontalFlip(p=0.5),
    #Convert the image to tensor
    transforms.ToTensor()
])

"""##Loading image data using 'ImageFolder'

We can load image classification data using 'torchvision.datasets.ImageFolder'
"""

from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir,
                                   transform=data_transform, #a transform for the data
                                   target_transform=None #a transform for the labels
                                   )
test_data = datasets.ImageFolder(root=test_dir,
                                   transform=data_transform, #a transform for the data
                                   target_transform=None #a transform for the labels
                                   )

class_names=train_data.classes

"""##Turn loaded images into DataLoader"""

import os

train_dataloader= DataLoader(dataset=train_data,
                             batch_size=32,
                             num_workers=os.cpu_count(), # no of cpu available
                             shuffle=True)
test_dataloader= DataLoader(dataset=test_data,
                             batch_size=32,
                             num_workers=os.cpu_count(),
                             shuffle=False)

img, label = next(iter(train_dataloader))

print(f"Image shape: {img.shape} -> [ batch_size, colour_channel, height, width]")
print(f"Label shape: {label.shape}")

"""##Augmentation

Trying out TrivialAugment that leverages the randomness and applies some random augmentation to our data.

Augmentations:
https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py

"""

from torchvision import transforms

train_transform = transforms.Compose([
    transforms.Resize(size=(224,224)),
    transforms.TrivialAugmentWide(num_magnitude_bins=32), # data augmentation, the lower the number of bins the less the maximum upper bound of transformation will be
    transforms.ToTensor()
    ])

test_transform = transforms.Compose([
    transforms.Resize(size=(224,224)),
    transforms.ToTensor()
    ])

"""##Model 0 : TinyVGG without Data Augmentation
Trying to replicate TinyVGG architecture from the CNN Explainer website: https://poloclub.github.io/cnn-explainer/

### Creating transforms and loading data for Model 0
"""

simple_transform = transforms.Compose([
    transforms.Resize(size=(256,256)),
    transforms.ToTensor()
])

# Load and transform data
from torchvision import datasets
train_data_simple = datasets.ImageFolder(root=train_dir,
                                   transform=simple_transform,
                                   target_transform=None
                                   )
test_data_simple = datasets.ImageFolder(root=test_dir,
                                   transform=simple_transform,
                                   target_transform=None
                                   )
# Turn dataset into Dataloader
from torch.utils.data import DataLoader
train_dataloader_simple = DataLoader(dataset=train_data_simple,
                                     batch_size=32,
                                     num_workers=os.cpu_count(),
                                     shuffle=True)
test_dataloader_simple = DataLoader(dataset=test_data_simple,
                                     batch_size=32,
                                     num_workers=os.cpu_count(),
                                     shuffle=False)

"""### Create Tiny VGG Model Class"""

class TinyVGG(nn.Module):
    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):
        super().__init__()
        self.conv_block_1 = nn.Sequential(
            nn.Conv2d(in_channels=input_shape,
                      out_channels=hidden_units,
                      kernel_size=3,
                      stride=1,
                      padding=1),
            nn.ReLU(),
            nn.Conv2d(in_channels=hidden_units,
                      out_channels=hidden_units*2,
                      kernel_size=3,
                      stride=1,
                      padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2,
                         stride=2) #default stride value = kernel size
        )

        self.conv_block_2 = nn.Sequential(
            nn.Conv2d(in_channels=hidden_units*2,
                      out_channels=hidden_units*4,
                      kernel_size=3,
                      stride=1,
                      padding=1),
            nn.ReLU(),
            nn.Conv2d(in_channels=hidden_units*4,
                      out_channels=hidden_units*8,
                      kernel_size=3,
                      stride=1,
                      padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2,
                         stride=2)
        )

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(in_features=hidden_units*8*64*64, #Checkpoint
                      out_features=1024),
            nn.ReLU(),
            nn.Linear(in_features=1024,
                      out_features=512),
            nn.ReLU(),
            nn.Linear(in_features=512,
                      out_features=output_shape)

        )

    def forward(self, x):
        x = self.conv_block_1(x)
        #print(x.shape)
        x = self.conv_block_2(x)
        #print(x.shape)
        x = self.classifier(x)
        return x

model_0= TinyVGG(input_shape=3,
                 hidden_units=32,
                 output_shape=len(class_names)).to(device)

"""### Passing dummy data thru variable to put in Checkpoint two blocks above"""

image_batch, label_batch = next(iter(train_dataloader_simple))
image_batch.shape, label_batch.shape

# Pass image_batch or any other random tensor of size [32,3,64,64]
model_0(image_batch)  # Use the last size of output from Conv2d 2nd block to update input size at Checkpoint

"""### Use torchinfo to get an idea of shapes going through our model

"""

#Install torchinfo
try:
  import torchinfo
except:
  !pip install torchinfo
  import torchinfo

from torchinfo import summary
summary(model_0, input_size=(1, 3, 224, 224))

"""## Creating training and testing loop functions

'train_step()' - takes in a model and a dataloader and trains the model on the dataloader.
'test_step()' - takes in a model and dataloader and evaluates the mdoel on the dataloader.
"""

#Create train_step()
def train_step(model: torch.nn.Module,
               dataloader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               device=device):
  #Putting model in train mode
  model.train()

  #Setup train losss and train accuracy values
  train_loss, train_acc= 0,0

  #Loop through data loader data batches
  for batch, (X, y) in enumerate(dataloader):
    #Send data to target device
    X, y = X.to(device), y.to(device)

    #1. Forward pass
    y_pred = model(X)

    #2. Calculate loss
    loss = loss_fn(y_pred, y)
    train_loss += loss.item()

    #3. Optimizer zero grad
    optimizer.zero_grad()

    #4. Loss backward
    loss.backward()

    #5. Optimizer step
    optimizer.step()

    #Calculate accuracy
    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
    train_acc += (y_pred_class == y).sum().item()/len(y_pred)

  #Calculate train loss and accuracy per epoch
  train_loss = train_loss / len(dataloader)
  train_acc = train_acc / len(dataloader)
  return train_loss, train_acc

#Create a test step function
def test_step(model: torch.nn.Module,
               dataloader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               device=device):
  #Putting model in eval mode
  model.eval()

  #Setup test
  test_loss, test_acc = 0,0

  #Turn on inference mode
  with torch.inference_mode():
    # Loop through dataloader batches
    for batch, (X, y) in enumerate(dataloader):
      #Send data to target device
      X, y = X.to(device), y.to(device)

      #1. Forward pass
      test_pred_logits = model(X)

      #2. Calculate loss
      loss = loss_fn(test_pred_logits, y)
      test_loss += loss.item()

      #Calculate the accuracy
      test_pred_labels = test_pred_logits.argmax(dim=1)
      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))

    #Calculate test loss and accuracy per epoch
    test_loss = test_loss / len(dataloader)
    test_acc = test_acc / len(dataloader)
    return test_loss, test_acc

"""### Creating a train() function to combine train_step() and test_step()"""

from tqdm.auto import tqdm

def train(model,
          train_dataloader,
          test_dataloader,
          optimizer,
          loss_fn = nn.CrossEntropyLoss(),
          epochs:int=5,
          device=device):
  # Create a empty dictionary
  results = {"train_loss": [],
            "test_loss": [],
            "train_acc": [],
            "test_acc": []}

  # Loop through training and testing steps for epochs

  for epoch in tqdm(range(epochs)):
    train_loss, train_acc = train_step(model=model,
                                       dataloader=train_dataloader,
                                       loss_fn=loss_fn,
                                       optimizer=optimizer,
                                       device=device)
    test_loss, test_acc = test_step(model=model,
                                  dataloader=test_dataloader,
                                  loss_fn=loss_fn,
                                  device=device)

    # Print out what's happening
    print(f"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}")

    #Update results dictionary
    results["train_loss"].append(train_loss)
    results["train_acc"].append(train_acc)
    results["test_loss"].append(test_loss)
    results["test_acc"].append(test_acc)

  #Return the results  at the end of epochs
  return results

"""### Train and evaluate model 0"""

model_0 = TinyVGG(input_shape=3,
                  hidden_units=32,
                  output_shape=len(train_data.classes)).to(device)

#setup loss function and optimizer
loss_fn=nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(params=model_0.parameters(),
                           lr=0.001) # Adam's default learning rate
#Start the timer
from timeit import default_timer as timer
start_time=timer()

#Train model_0

model_0_results=train(model=model_0,
                      train_dataloader=train_dataloader_simple,
                      test_dataloader=test_dataloader_simple,
                      optimizer=optimizer,
                      loss_fn=loss_fn,
                      epochs=5)

#end the timer
end_time=timer()
print(f"Total training time: {end_time-start_time:.3f}")
model_0_results

"""## TinyVGG with Data Augmentation

Same model as before but with some data augmentation

### Create transform with data augmentation
"""

from torchvision import transforms
train_transform_trivial = transforms.Compose([
    transforms.Resize(size=(224,224)),
    transforms.TrivialAugmentWide(num_magnitude_bins=31),
    transforms.ToTensor()
    ])

test_transform_trivial = transforms.Compose([
    transforms.Resize(size=(224,224)),
    transforms.ToTensor()
    ])

"""### Create train and test Datasets and DataLoaders with data augmentation

"""

from torchvision import datasets
train_data_augmented = datasets.ImageFolder(root=train_dir,
                                   transform=train_transform_trivial,
                                   target_transform=None
                                   )
test_data_augmented = datasets.ImageFolder(root=test_dir,
                                   transform=simple_transform,
                                   target_transform=None
                                   )

# Turn out datasets into Dataloaders
import os
from torch.utils.data import DataLoader

train_dataloader_augmented= DataLoader(dataset=train_data_augmented,
                                     batch_size=32,
                                     num_workers=os.cpu_count(),
                                     shuffle=True)
test_dataloader_augmented= DataLoader(dataset=test_data_augmented,
                                     batch_size=32,
                                     num_workers=os.cpu_count(),
                                     shuffle=False)

"""### Construct and train Model 1
This time we will be using the same model architechture but this time we have augmented the training data
"""

# Create model_1 and send it to the target device

model_1=TinyVGG(input_shape=3,
                hidden_units=10,
                output_shape=len(train_data_augmented.classes)).to(device)

"""Loss function and optimizer and call upon our train function to train and evaluate our model"""

loss_fn= nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(params=model_0.parameters(),
                           lr=0.001)

# Start the timer
from timeit import default_timer as timer
start_time=timer()

#Train model 1
model_1_results = train(model=model_0,
                      train_dataloader=train_dataloader_augmented,
                      test_dataloader=test_dataloader_simple,
                      optimizer=optimizer,
                      loss_fn=loss_fn,
                      epochs=5,
                      device=device)
#End the timer
end_time=timer()
print(f"Total training time for model 1: {end_time - start_time:.3f} seconds")





